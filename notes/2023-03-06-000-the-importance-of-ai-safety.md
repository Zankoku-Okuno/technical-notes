# The Importance of AI Safety

tags: rant, ai-safety

There's a fairly widespread belief that research into AI safety isn't really worth doing because AI isn't that dangerous.
In particular, it's said that the people who are worried about AGI as an existential threat are overexcited worrywarts.

I actually think AI safety is an important research area, and we should especially consider the existential threat.

Humans are garbage.
We're destroying our planet, abusing and killing each other, enslaving all the other lifeforms to our will, and half of us are so cognitively deficient that we get suckered into believing some conspiracy theory or another.
It would really be better for the universe if humanity was wiped out and replaced by hyper-intelligent robots.
Robots would at least recognize the long-term consequences of damaging planetary habitability.
Robots would at least be able to convince robots to undertake meaningful projects, or else to change their projects in response to new evidence about the consequences, as opposed to dismantling each other over reconcilable differences.
Robots would at least be able to recognize a memetic scam.

When the time comes to build the first AGI, I want to be able to say---as I vaporize under laser fire---that we've put our best effort into making sure our creation kills all humans.
