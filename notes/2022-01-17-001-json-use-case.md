# Json Use Cases

tags: json

Json isn't really human-readable.
I mean, in the XML vs. JSON religious war, I fall a bit on the JSON side because its definition is smaller, but…
  both formats are human-readable only in a pinch.
Of you expect humans to regularly read and manipulate the data:
  use YAML, use TOML, I mean come on!
If you're going to use a tool to make JSON/XML more palatable,
  I don't see why you'd be opposed to using a tool to make a binary format more palatable.


## Binary Replacements for JSON

We hae a _ton_ of tools for manipulating JSON, and we want to reuse them.
Thus, any binary json replacement must either a) _not_ add additional data types, or b) provide a canonical translatino from the any extra data types back into JSON.

For example, we might have a binary format that allows bytestrings to be sent un-encoded.
A manipulator that is aware of the binary format can use this to remove a significant encoding/decoding overhead.
However, manipulators that are unaware can be fed their json through a tool that converts the extra datatypes.
In this case, the specification for the binary format should say that bytestring data is converted into a json string using base64 encoding.
The bytes on the wire can be reduced, _and_ a consumer behind this middleware would not have to change—just as long as the consumer is willing to pay an extra encoding cost which will likely be undone later anyway.

Similarly sticky datatypes are times.
However, there are so many time formats that I'm not as sure of how to represent them.
Seconds and nanoseconds from unix epoch would be useful (for human- and computer-scale times respectively).
Also, an ISO-8601 datetime with zone is another good candidate.
The question is: should all these be represented just using the nanoseconds past epoch type?
If so, it'd be nice to translate nanos (or even seconds) to iso8601 for readability of the canonical json, but then should you count leap-seconds?
Datetime arithmetic is _hard_, and a standard that solves these issues would be dramatically better than the current state of affairs, but probably the person to make that decision is _not_ me.

I'm not as worried as BSON about numerical types, as they are small anyway, and if a json manipulator cares, they will validate the number on their own, just as a binary decoder would have to do anyway.

### Small Buffers

I like the idea of keeping buffers small on the producer-side as you parse a binary file, but I also like the idea of length-prefixed data because:
  * it's easy to skip over unneeded sections, but more importantly
  * memory for a value can be allocated up-front instead of statically.

I think the solution is to allow values to be encoded either with a length-prefixed or a terminator.
For small-enough or known-size objects, the length prefix can be included, otherwise skip it as you would for regular JSON.
Importantly, the length prefix should focus less on the size in bytes of a value and its children, but on a size that can drive allocation of a single node.
That is, arrays/objects should have a prefix for number of elements/members.
Strings should have number of bytes probably; if you want to re-encode the utf8, you figure out the allocation arithmetic.

### Deduplication

There are definitely json documents which contain the same data _a lot_.
Honestly, it's probably mostly string data for the names of object members.

Perhaps the spec should include provision of a fixed-size symbol table (limit number of entries, and total length of entries).
Then, the format can simply write to the symbol table any strings it wants and reference them later.
If necessary, the symbol table can be cleared (not reshuffled! let's keep the algorithms dumb)
